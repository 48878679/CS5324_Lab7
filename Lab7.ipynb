{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2ae683c",
   "metadata": {},
   "source": [
    "## Lab 7, Group 1\n",
    "### Names: Hailey DeMark, Deborah Park, Karis Park\n",
    "### Student IDs: 48869449, 48878679, 48563429\n",
    "\n",
    "Dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76a7a53",
   "metadata": {},
   "source": [
    "## Preparation (3 points total)\n",
    "* [1 points] Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed). Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created). Discuss methods of tokenization in your dataset as well as any decisions to force a specific length of sequence.  \n",
    "    * For this lab, we chose a text dataset made up of SMS messages. Each message is labeled as either \"spam\" (unwanted messages) or \"ham\" (normal messages). The dataset is already split into two parts: a training set with 957 messages and a test set with 125 messages. Each row in the data has a message and a label. We will turn the labels into numbers — \"spam\" will be 1 and \"ham\" will be 0 — so we can use them in a machine learning model. To prepare the messages, we will use a tokenizer to turn each message into a list of numbers. Then we will make all messages the same length by adding padding, so they can be used in a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c2f6cb",
   "metadata": {},
   "source": [
    "* [1 points] Choose and explain what metric(s) you will use to evaluate your algorithm’s performance. You should give a detailed argument for why this (these) metric(s) are appropriate on your data. That is, why is the metric appropriate for the task (e.g., in terms of the business case for the task). Please note: rarely is accuracy the best evaluation metric to use. Think deeply about an appropriate measure of performance.\n",
    "    * // answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47669814",
   "metadata": {},
   "source": [
    "* [1 points] Choose the method you will use for dividing your data into training and testing (i.e., are you using Stratified 10-fold cross validation? Shuffle splits? Why?). Explain why your chosen method is appropriate or use more than one method as appropriate. Convince me that your train/test splitting method is a realistic mirroring of how an algorithm would be used in practice.\n",
    "    * We will use the training and test split that’s already given to us. This is a good way to model a real-life situation — we train the model on past data and test it on new messages. While training, we might also use another method called stratified K-Fold cross-validation on just the training data. This helps us get a better idea of how the model performs, especially when the number of spam and normal messages are very different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8803b0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('SMS_train.csv', encoding='cp1252')\n",
    "test_df = pd.read_csv('SMS_test.csv', encoding='cp1252')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a05ee54",
   "metadata": {},
   "source": [
    "## Modeling (6 points total)\n",
    "* [3 points] Investigate at least two different sequential network architectures (e.g., a CNN and a Transformer). Alternatively, you may also choose a recurrent network and Transformer network. Be sure to use an embedding layer (try to use a pre-trained embedding, if possible). Adjust one hyper-parameter of each network to potentially improve generalization performance (train a total of at least four models). Visualize the performance of training and validation sets versus the training iterations, showing that the models converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ab11bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a825e8a9",
   "metadata": {},
   "source": [
    "* [1 points] Using the best parameters and architecture from the Transformer in the previous step, add a second Multi-headed self attention layer to your network. That is, the input to the second attention layer should be the output sequence of the first attention layer.  Visualize the performance of training and validation sets versus the training iterations, showing that the model converged.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fbc7514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15e23f7",
   "metadata": {},
   "source": [
    "* [2 points] Use the method of train/test splitting and evaluation criteria that you argued for at the beginning of the lab. Visualize the results of all the models you trained.  Use proper statistical comparison techniques to determine which method(s) is (are) superior.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22fb7a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8a25aa",
   "metadata": {},
   "source": [
    "## Exceptional Work (1 points total)\n",
    "* You have free reign to provide additional analyses.\n",
    "* One idea (required for 7000 level students to do one of these options):\n",
    "    * Use the pre-trained ConceptNet Numberbatch embedding and compare to pre-trained GloVe. Which method is better for your specific application? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "920e4bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
